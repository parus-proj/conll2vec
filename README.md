В процессе разработки!!!


# conll2vec
conll2vec — утилита для построения векторных представлений слов на основе морфологически и синтаксически размеченных данных в формате [conll](https://universaldependencies.org/format.html).

В ходе обучения conll2vec одновременно оперирует синтаксическим и оконным контекстом. Часть измерений векторного представления обучается на синтаксических контекстах, часть — на традиционных для [word2vec](https://ru.wikipedia.org/wiki/Word2vec)-утилит линейно-оконных контекстах. Синтаксический контекст слова определяется по дереву зависимостей. Для каждого слова отыскиваются его ближайшие соседи в синтаксическом дереве (родитель и ближайшие потомки). Контекстными единицами выступают тройки <лемма слова-соседа, направление синтаксической связи, тип синтаксического отношения>. Для линейно-оконных контекстов размер окна приравнивается размеру предложения. Контекстными единицами выступают леммы слов.

Утилита строит отдельные векторные представления для нарицательных и собственных имён. Нарицательные *клин*, *орел*, *курган*, *газ*, *калина*, *сапсан* и многие другие имеют омонимы среди собственных имён. Морфологическая информация в conll-данных позволяет различать такого рода омонимы и строить для них отдельные представления. Включение собственных имён в векторную модель опционально (выполняется отдельной фазой обучения).

## Быстрый старт
В репозитории размещены демонстрационные скрипты для Linux и Windows, обеспечивающие:
1. сборку утилит из исходных кодов, 
2. построение векторной модели на основе фрагмента данных из корпуса [PaRuS](https://parus-proj.github.io/PaRuS),
3. запуск утилиты в интерактивном режиме — для заданного слова отыскиваются ближайшие по смыслу.

Для сборки утилит требуется компилятор с поддержкой [C++17](https://ru.wikipedia.org/wiki/C%2B%2B17). Сборка протестирована под Linux с компилятором gcc v7.5.0 и под Windows с компилятором от Visual Studio 2017 v15.9.14 (cl.exe версии 19.16).

<table>
  <tr>
    <th width="50%">Запуск под Linux</th>
    <th>Запуск под Windows</th>
  </tr>
  <tr>
    <td valign="top">Запустите консоль. Перейдите в директорию, в которой хотите развернуть программное обеспечение.</td>
    <td>Запустите «Командную строку разработчика для VS 2017» (это обеспечит настройку окружения для сборки утилит). Перейдите в папку, в которой хотите развернуть программное обеспечение.</td>
  </tr>
  <tr>
    <td colspan="2" align="center">git clone https://github.com/parus-proj/conll2vec.git<br/>cd conll2vec</td>
  </tr>
  <tr>
    <td align="center">./demo-linux.sh</td>
    <td align="center">demo-windows.cmd</td>
  </tr>
  <tr>
    <td colspan="2">При успешных сборке и обучении работа скрипта завершится вызовом утилиты в режиме поиска слов с близким значением. Чтобы удостовериться в работоспособности, попробуйте ввести распространённые слова — <i>президент</i>, <i>автомобиль</i>, <i>телефон</i>. Отмечу, что демонстрационный скрипт порождает неоптимальную векторную модель, чтобы сократить время обучения. Для построения высококачественной модели необходимо использовать больший объём данных из корпуса [PaRuS](https://parus-proj.github.io/PaRuS) или иного крупного conll-дейтасета.</td>
  </tr>
</table>

## TODO: Режимы работы и параметры утилиты

Про режимы запуска утилиты.
Осуществляет построение векторных представлений слов языка в соответствии с моделью обучения Skip-gram.
Для каждого введённого пользователем слова утилита находит в векторной модели близкие по значению слова, а также показывает количественную меру близости ([косинусная мера](https://en.wikipedia.org/wiki/Cosine_similarity)).

Параметры утилиты:

<table>
  <tr>
    <td>-train</td><td>имя файла, содержащего обучающее множество;</td>
  </tr>
  <tr>
    <td>-words-vocab</td><td>имя файла, содержащего словарь, построенный утилитой build_dict;</td>
  </tr>
  <tr>
    <td>-output</td><td>имя файла, куда будут сохранены векторные представления слов. Файл имеет бинарный формат, полностью совместимый с word2vec;</td>
  </tr>
  <tr>
    <td>-size</td><td>размерность результирующих векторов для представления слов (размерность эмбеддинга);</td>
  </tr>
  <tr>
    <td>-window</td><td>размер окна, задающего контекст слова;</td>
  </tr>
  <tr>
    <td>-optimization</td><td>метод оптимизации вычислений. Значение <i>hs</i> соответствует hierarchical softmax, значение <i>ns</i> соответствует negative sampling. В отличие от оригинального word2vec, можно использовать только один из методов;</td>
  </tr>
  <tr>
    <td>-negative</td><td>(для метода negative sampling) количество отрицательных примеров, противопоставляемых каждому положительному примеру. Иными словами, количество слов, выбираемых из noise distribution;</td>
  </tr>
  <tr>
    <td>-iter</td><td>количество эпох обучения;</td>
  </tr>
  <tr>
    <td>-sample</td><td>коэффициент прореживания. Обеспечивает снижение в обучающем множестве доли частотных слов. По умолчанию 1e-3;</td>
  </tr>
  <tr>
    <td>-alpha</td><td>начальное значение скорости обучения;</td>
  </tr>
  <tr>
    <td>-threads</td><td>количество потоков управления, параллельно выполняющих обучение модели.</td>
  </tr>
</table>
